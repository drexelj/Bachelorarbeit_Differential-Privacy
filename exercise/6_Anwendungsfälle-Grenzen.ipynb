{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81435a5",
   "metadata": {},
   "source": [
    "### Musterlösung zu den Kontrollfragen des vorherigen Notebooks\n",
    "\n",
    "* Es soll aus einer Datensammlung der häufigste Zivilstand ausgegeben werden. Welcher Mechanismus ist dafür am besten geeignet?\n",
    "> Der exponentielle Mechanismus, da die Ausgabe nicht-numerisch ist, wie z.B. \"ledig\" oder \"verheiratet\", etc.\n",
    "\n",
    "* Was könnte für den oben genannten Fall als Bewertungsfunktion verwendet werden?\n",
    "> Die Anzahl Personen jedes Zivilstands.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc8b4e",
   "metadata": {},
   "source": [
    "# Notebook 6: Anwendungsfälle und Grenzen der Differential Privacy\n",
    "\n",
    "***Hier geht es zum vorherigen Notebook dieser Serie: [Notebook 5: Der exponentielle Mechanismus](./5_Exponentieller-Mechanismus.ipynb)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99181154",
   "metadata": {},
   "source": [
    "## Lernziele\n",
    "\n",
    "Folgende Lernziele sollten mit der Bearbeitung dieses Jupyter Notebooks erreicht werden können:\n",
    "- Die Teilnehmenden sind in der Lage, die verschiedenen Anwendungsfälle der Differential Privacy zu benennen.\n",
    "- Die Teilnehmenden sind in der Lage, die Grenzen der Differential Privacy zu benennen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d687c",
   "metadata": {},
   "source": [
    "## Anwendungsfälle der Differential Privacy\n",
    "\n",
    "Die Anwendungsfälle von Differential Privacy sind sehr vielfältig. Grundsätzlich kann die Definition von Differential Privacy für sämtliche Funktionen angewendet werden, welche auf Datensammlungen zugreifen, Daten sammeln oder veröffentlichen.\n",
    "\n",
    "Folgend sind einige Anwendungsfälle aufgeführt:\n",
    "\n",
    "- **Statistische Analysen:** Es wird eine Schnittstelle angeboten, welche es erlaubt Abfragen zu tätigen. Die Antworten werden von einem Mechanismus zurückgegeben, welcher die Eigenschaften von Differential Privacy erfüllt.\n",
    "- **Veröffentlichung von Daten / Statistiken:** Die Daten / Statistiken werden vor der Veröffentlichung durch einen Mechanismus aufbereitet, welcher die Eigenschaften der Differential Privacy erfüllt.\n",
    "- **Generieren von synthetischen Daten:** Synthetische Daten sind künstlich erzeugte Daten, welche aber im Optimalfall die Eigenschaften von realen Daten aufweisen. Synthetischen Daten können beispielsweise für Softwaretests genutzt werden, um in der Testumgebung nicht mit echten Daten arbeiten zu müssen. Es kann ein Mechanismus implementiert werden, welcher aus der originalen Datensammlung eine synthetische Datensammlung generiert. Dieser Mechanismus wird so implementiert, dass dieser die Eigenschaften von Differential Privacy erfüllt. So kann die Privacy der in der originalen Datensammlung enthaltenen Individuen gewahrt werden.\n",
    "- **Machine Learning:** Machine Learning Algorithmen funktionieren, indem sie eine grosse Menge von Daten untersuchen und versuchen daraus Erkenntnisse zu ziehen bzw. Modelle zu errechnen. Das Ziel von Machine Learning ist es, dass allgemeingültige Muster erkannt werden und nicht die Erkenntnisse über einzelne Individuen in das Modell einfliessen. Hier kann die Differential Privacy einen grossen Mehrwert erbringen. Es wird über einen Mechanismus auf die Trainingsdaten zugegriffen, welcher die Eigenschaften der Differential Privacy erfüllt und verhindert, dass Erkenntnisse über einzelne Individuen ins Modell einfliessen.\n",
    "- **Data Mining / Recommender System:** Beim Data Mining wird eine grosse Datenmenge statistisch untersucht, um neue Verbindungen und Trends zu erkennen. Ein Recommender System ist ein System, welches basierend auf historischen Benutzerdaten versucht die Interessen und potentiellen Aktionen eines Benutzenden vorauszusagen bzw. Empfehlungen abgeben zu können. Um zu verhindern, dass aus diesen Daten Erkenntnisse über Individuen gewonnen werden können, wird dem Data Miner der Zugriff auf die Daten nur über einen Mechanismus ermöglicht, welcher die Eigenschaften der Differential Privacy erfüllt.\n",
    "\n",
    "Diese Liste ist nicht abschliessend. Sie zeigt aber, dass die Differential Privacy in vielen verschiedenen Themenfeldern Anwendung finden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d58f422",
   "metadata": {},
   "source": [
    "## Grenzen der Differential Privacy\n",
    "\n",
    "Die Möglichkeiten und Einsatzgebiete der Differential Privacy scheinen unbegrenzt und es könnte geschlussfolgert werden, dass die Differential Privacy sämtliche bisherigen Konzepte zum Schutz der Privacy ersetzen könnte. Aus diesem Grund ist es wichtig die Grenzen der Differential Privacy zu betrachten und deren Anwendungen kritisch zu hinterfragen.\n",
    "\n",
    "Domingo-Ferrer, Sánchez und Blanco-Justicia äussern in <a href=\"https://arxiv.org/pdf/2011.02352.pdf\">ihrem Paper</a> deutliche Kritik, dass die Differential Privacy gerade von den grossen Technologie-Konzernen oftmals missbraucht und als Tarnung für \"gute Privacy\" verwendet wird. Apple soll Privacy-Budgets von $\\varepsilon = 4$ und $\\varepsilon = 16$ verwenden. Solch hohe Privacy-Budgets werden als sinnlos eingeschätzt. Die Privacy wird dadurch nicht genügend geschützt. \n",
    "\n",
    "Weiter werden nach Domingo-Ferrer, Sánchez und Blanco-Justicia für Machine Learning Anwendungen sehr hohe Privacy-Budgets benötigt, um sinnvolle Ergebnisse zu erzielen. Deshalb ist die Verwendung von Differential Privacy für Machine Learning anspruchsvoll und nicht in jedem Fall sinnvoll.\n",
    "\n",
    "Ein weiterer wichtiger Punkt den es zu beachten gilt, ist die Wahl des Privacy-Budgets bei Kompositionen von mehreren Mechanismen. Dies ist besonders beim kontinuierlichen Sammeln von Daten ein Knackpunkt. Werden beispielsweise laufend Benutzerdaten über die Verwendung der Emojis (wie Apple dies macht) gesammelt, so müsste für jede einzelne Übermittlung ein eigenes Privacy-Budget alloziert werden. Da diese Daten zu demselben Individuum gehören, kommt die sequentielle Komposition zum Zug, bei welcher die einzelnen Privacy-Budgets aufsummiert werden. Die strikte Definition von Differential Privacy erlaubt somit kein kontinuierliches Sammeln von Daten, da zu Beginn das Gesamt-Privacy-Budget (der Komposition) bestimmt werden müsste. Apple hat deshalb die Definition soweit vereinfacht, dass nur für Daten innerhalb desselben Tages die sequentielle Komposition gilt, was eine weitere Schwächung des Privacy-Schutzes darstellt.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Wichtige Erkenntnis</b>\n",
    "    <br />\n",
    "    <br /> \n",
    "Es ist essentiell, dass das Privacy-Budget sinnvoll und durchdacht gewählt und strikt eingehalten wird. Nur bei einem entsprechend tiefen Privacy-Budget wird auch ein guter Schutz der Privacy garantiert. Es ist wichtig für jeden Anwendungsfall kritisch zu hinterfragen, ob das Konzept der Differential Privacy sinnvoll umgesetzt werden kann.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f96e1b",
   "metadata": {},
   "source": [
    "# Abschluss der Übungsserie\n",
    "\n",
    "Dies ist das Ende der Übungsserie. Sollte der Hirnspeicher nun überfüllt sein und das Löschen von Inhalten ist zwingend notwendig, sollten zumindest die folgenden wichtigen Erkenntnisse aus dieser Serie noch erhalten bleiben:\n",
    "\n",
    "- Die Differential Privacy beschreibt die Eigenschaften einer Funktion (Mechanismus) und nicht die Eigenschaften einer Datensammlung (wie bspw. bei der k-Anonymität).\n",
    "- Nur weil die Eigenschaften von Differential Privacy erfüllt sind, heisst das nicht zwingend, dass auch ein guter Schutz der Privacy gegeben sein muss. Wie gut die Privacy geschützt wird, bestimmt das Privacy-Budget. Wird dieses Budget falsch (also zu hoch) festgelegt, kann dies zu unzureichendem Schutz der Privacy führen.\n",
    "- Je kleiner das $\\varepsilon$ (Privacy-Budget), umso höher der Schutz der Privacy.\n",
    "- Wird derselbe Mechanismus mehrmals ausgeführt, kommt die Komposition des Privacy-Budgets zum Zug.\n",
    "- Je grösser die Datensammlung ist, umso besser funktioniert die Differential Privacy.\n",
    "- Es ist essentiell, dass das Privacy-Budget sinnvoll und durchdacht gewählt und strikt eingehalten wird. Nur bei einem entsprechend tiefen Privacy-Budget wird auch ein guter Schutz der Privacy garantiert. Es ist wichtig für jeden Anwendungsfall kritisch zu hinterfragen, ob das Konzept der Differential Privacy sinnvoll umgesetzt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ccebb",
   "metadata": {},
   "source": [
    "***Hier geht es zurück zur Übersicht: [Notebook 0: Übersicht und Inhalt](./0_Übersicht-und-Inhalt.ipynb)***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
